{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "attempt1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "interpreter": {
      "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
    },
    "kernelspec": {
      "display_name": "Python 3.8.10 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "orig_nbformat": 4
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lx2nbe5zZ_-N"
      },
      "source": [
        "# AskReddit Troll Question Detection Challenge"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KXFHvvFiZ_-U"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fhlIiuWBZ_-U"
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "import sklearn\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import re"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KDrBqoiNZ_-X",
        "outputId": "d74829d3-508d-4300-d936-715730d19fed"
      },
      "source": [
        "\n",
        "import nltk # for tokenizing the paragraphs in sentences and sentences in words\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ocHtsZhZ_-X",
        "outputId": "536ca71c-e8d2-4b62-b085-1094554c585a"
      },
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBUkOv3-Z_-Z"
      },
      "source": [
        "train_df = pd.read_csv(\"/content/drive/MyDrive/AskReddit_Dataset/train.csv\")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_J94ZCTaZ_-Z"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLiW_3JiZ_-a"
      },
      "source": [
        "### Dropping the qid"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cx1MhOldZ_-b"
      },
      "source": [
        "train_df.drop(columns=[\"qid\"],inplace=True)\n",
        "sentences = train_df['question_text'].tolist()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZ3OL3ubZ_-c"
      },
      "source": [
        "N = 653061\n",
        "sentences = sentences[0:N]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-VUUbh5Z_-c"
      },
      "source": [
        "### Cleaning the data\n",
        "\n",
        "- Like removing !?., etc.\n",
        "- converting sentences to lower case"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDlxrDDYZ_-d"
      },
      "source": [
        "# i=0\n",
        "# for sentence in sentences:\n",
        "#     temp = re.sub('[^a-zA-Z0-9]', ' ', sentence)\n",
        "#     temp = temp.lower()\n",
        "#     new_sentence = temp.split()\n",
        "#     new_sentence = ' '.join(new_sentence)\n",
        "#     sentences[i] = new_sentence\n",
        "#     # print(new_sentence)\n",
        "#     i+=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SGCFlwCKZ_-e"
      },
      "source": [
        "## Vectoring Words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7Q_4MUsZ_-f"
      },
      "source": [
        "#### Bag Of Words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2wvKev9Z_-f"
      },
      "source": [
        "# TODO max_features = 1500 may need to be altered\n",
        "cv = CountVectorizer()\n",
        "X1 = cv.fit_transform(sentences)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmSDQ3SQcgM0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9ce9d98-4ad2-4ff8-f881-6449d034d198"
      },
      "source": [
        "print(type(X1))\n",
        "print(X1.dtype)\n",
        "X1 = X1.astype(float)\n",
        "print(X1.dtype)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'scipy.sparse.csr.csr_matrix'>\n",
            "int64\n",
            "float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IW7S45TpnoLu"
      },
      "source": [
        "Y1 = train_df['target'].to_numpy().astype(np.float64)\n",
        "Y1 = Y1[:N]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-DL54RsIZ_-f"
      },
      "source": [
        "#### TF IDF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mslJKymTZ_-f"
      },
      "source": [
        "cv = TfidfVectorizer()\n",
        "X2 = cv.fit_transform(sentences)\n",
        "# print(X2)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lj34PL32colU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1dd2c7d-0982-4f8f-c9f8-77e1bd560dc0"
      },
      "source": [
        "print(type(X2))\n",
        "X2 = X2.astype(float)\n",
        "print(X2.dtype)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'scipy.sparse.csr.csr_matrix'>\n",
            "float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFKeWdk0oTw6"
      },
      "source": [
        "Y2 = Y1"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LWB94h8TZ_-g"
      },
      "source": [
        "#### Train test split data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bsgQdc0DZ_-g"
      },
      "source": [
        "from sklearn.model_selection import train_test_split \n",
        "\n",
        "train_X1, test_X1, train_y1, test_y1 = train_test_split(X1, Y1, train_size=0.6)\n",
        "\n",
        "train_X2, test_X2, train_y2, test_y2 = train_test_split(X2, Y2, train_size=0.6)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eze130ezqBb_"
      },
      "source": [
        "## Model generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rn2kPLNFpKIB"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression \n",
        "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9GvolAmhjQ1"
      },
      "source": [
        "### Logistic regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E6rUXyvQqIm-"
      },
      "source": [
        "#### For data genrated by \"Bag of words\" method  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xuwqd1rAp3dd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "683a5433-021b-4854-db12-dcfdeb90fe88"
      },
      "source": [
        "lreg1 = LogisticRegression(solver='liblinear')\n",
        "lreg1.fit(train_X1,train_y1)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RUYqt4NSqU2n"
      },
      "source": [
        "#### For data generated by \"TD IDF\" method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGQrUb81p6yD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ed3033c-eb4f-4394-e611-fcdb114f366b"
      },
      "source": [
        "lreg2 = LogisticRegression(solver='liblinear')\n",
        "lreg2.fit(train_X2,train_y2)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9l8Fkxpa16hQ"
      },
      "source": [
        "#### Predict for X1, Y1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LUEcmzS71ogz"
      },
      "source": [
        "train_yhat1 = lreg1.predict_proba(train_X1)\n",
        "test_yhat1 = lreg1.predict_proba(test_X1)\n",
        "\n",
        "# print(\"training score = \", roc_auc_score(train_y1, train_yhat1[:,1]))\n",
        "# print(\"test score = \", roc_auc_score(test_y1,test_yhat1[:,1]))\n",
        "\n",
        "threshold = 0.225\n",
        "\n",
        "train_output1 = (train_yhat1[:,1] > threshold).astype(int)\n",
        "test_output1 = (test_yhat1[:,1] > threshold).astype(int)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bn5zqugWgl8f",
        "outputId": "50ad8ab1-f0c8-408c-b52c-9c0983e3aaeb"
      },
      "source": [
        "print(\"training score = \", f1_score(train_y1.astype(int), train_output1))\n",
        "print(\"testing score = \", f1_score(test_y1.astype(int), test_output1))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training score =  0.714859135023085\n",
            "testing score =  0.6119907894362794\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qE74zYa62MfV"
      },
      "source": [
        "#### Predict for X2, Y2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vdTbUQBz2QkI"
      },
      "source": [
        "train_yhat2 = lreg2.predict_proba(train_X2)\n",
        "test_yhat2 = lreg2.predict_proba(test_X2)\n",
        "\n",
        "# print(\"training score = \", roc_auc_score(train_y2, train_yhat2[:,1]))\n",
        "# print(\"test score = \", roc_auc_score(test_y2,test_yhat2[:,1]))\n",
        "\n",
        "threshold = 0.2\n",
        "\n",
        "train_output2 = (train_yhat2[:,1] > threshold).astype(int)\n",
        "test_output2 = (test_yhat2[:,1] > threshold).astype(int)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5gl_S4DCgl8g",
        "outputId": "770ea64b-ccd4-4147-8214-7492a17a587d"
      },
      "source": [
        "print(\"training score = \", f1_score(train_y2.astype(int), train_output2))\n",
        "print(\"testing score = \", f1_score(test_y2.astype(int), test_output2))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training score =  0.6497909728619004\n",
            "testing score =  0.602790094084568\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ozmrruZ3h6Zm"
      },
      "source": [
        "### Bernoulli NB model generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERj5MSX-i7sq"
      },
      "source": [
        "from sklearn.naive_bayes import BernoulliNB"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yoMj9zI7jQJm"
      },
      "source": [
        "#### Bag of words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KFOknkNbjOs_",
        "outputId": "11948792-ef18-4234-c4e4-934e549d9d6a"
      },
      "source": [
        "clf1 = BernoulliNB()\n",
        "\n",
        "# print(type(train_X1))\n",
        "clf1.fit(train_X1,train_y1)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cUZ8ocA7kI85"
      },
      "source": [
        "#### TD IDF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sSff06sQkHzc",
        "outputId": "a3858700-2f80-4403-ca2a-5551a2a855d4"
      },
      "source": [
        "clf2 = BernoulliNB()\n",
        "clf2.fit(train_X2,train_y2)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eY_umWbQkcjs"
      },
      "source": [
        "### BernoulliNB Prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xLHyJ0Byklq7"
      },
      "source": [
        "#### Bag of words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RcUzY8GUkpVe"
      },
      "source": [
        "train_yhat1 = clf1.predict_proba(train_X1)\n",
        "test_yhat1 = clf1.predict_proba(test_X1)\n",
        "\n",
        "# print(\"training score = \", roc_auc_score(train_y1, train_yhat1[:,1]))\n",
        "# print(\"test score = \", roc_auc_score(test_y1,test_yhat1[:,1]))\n",
        "\n",
        "threshold = 0.225\n",
        "\n",
        "train_output1 = (train_yhat1[:,1] > threshold).astype(int)\n",
        "test_output1 = (test_yhat1[:,1] > threshold).astype(int)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ULB8BhFTk2IL",
        "outputId": "50eaac4c-5b4a-489e-8687-60b6668f2503"
      },
      "source": [
        "print(\"training score = \", f1_score(train_y1.astype(int), train_output1))\n",
        "print(\"testing score = \", f1_score(test_y1.astype(int), test_output1))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training score =  0.5428327446337772\n",
            "testing score =  0.5142079292155862\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kjvJpVnJk4t8"
      },
      "source": [
        "#### TD IDF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dR2jH1jxk8t8"
      },
      "source": [
        "train_yhat2 = clf2.predict_proba(train_X2)\n",
        "test_yhat2 = clf2.predict_proba(test_X2)\n",
        "\n",
        "# print(\"training score = \", roc_auc_score(train_y2, train_yhat2[:,1]))\n",
        "# print(\"test score = \", roc_auc_score(test_y2,test_yhat2[:,1]))\n",
        "\n",
        "threshold = 0.2\n",
        "\n",
        "train_output2 = (train_yhat2[:,1] > threshold).astype(int)\n",
        "test_output2 = (test_yhat2[:,1] > threshold).astype(int)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KaYrbAbklAFM",
        "outputId": "b2795953-fb14-427a-a266-683495151228"
      },
      "source": [
        "print(\"training score = \", f1_score(train_y2.astype(int), train_output2))\n",
        "print(\"testing score = \", f1_score(test_y2.astype(int), test_output2))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training score =  0.5469071678156577\n",
            "testing score =  0.5090531398253937\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7uBeMgKSpKCB"
      },
      "source": [
        "### Perceptron model generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZaQ7L53pSzE"
      },
      "source": [
        "from sklearn.linear_model import Perceptron"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qYRVFQtpkQ9"
      },
      "source": [
        "#### Bag of words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4dg_fGAsplhl",
        "outputId": "f4c5c774-2ed7-46df-d3cb-41d3111f0e42"
      },
      "source": [
        "clf1 = Perceptron(tol=1e-3, random_state=0)\n",
        "\n",
        "# print(type(train_X1))\n",
        "clf1.fit(train_X1,train_y1)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Perceptron(alpha=0.0001, class_weight=None, early_stopping=False, eta0=1.0,\n",
              "           fit_intercept=True, max_iter=1000, n_iter_no_change=5, n_jobs=None,\n",
              "           penalty=None, random_state=0, shuffle=True, tol=0.001,\n",
              "           validation_fraction=0.1, verbose=0, warm_start=False)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ym-c6UAJp7Xu"
      },
      "source": [
        "#### TD IDF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wKSi2aWtp8aW",
        "outputId": "28a14112-3ec6-4363-b5bb-215eebde25cf"
      },
      "source": [
        "clf2 = Perceptron(tol=1e-3, random_state=0)\n",
        "clf2.fit(train_X2,train_y2)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Perceptron(alpha=0.0001, class_weight=None, early_stopping=False, eta0=1.0,\n",
              "           fit_intercept=True, max_iter=1000, n_iter_no_change=5, n_jobs=None,\n",
              "           penalty=None, random_state=0, shuffle=True, tol=0.001,\n",
              "           validation_fraction=0.1, verbose=0, warm_start=False)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rkgzOYEvqLwi"
      },
      "source": [
        "### Perceptron Prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EoZlOJ0NqQMR"
      },
      "source": [
        "#### Bag of words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-t7ZFqDrqOaC",
        "outputId": "650909a3-3cd1-4780-c17c-68f15af2de0e"
      },
      "source": [
        "train_yhat1 = clf1.predict(train_X1)\n",
        "test_yhat1 = clf1.predict(test_X1)\n",
        "\n",
        "print(train_yhat1.shape)\n",
        "\n",
        "# print(\"training score = \", roc_auc_score(train_y1, train_yhat1[:,1]))\n",
        "# print(\"test score = \", roc_auc_score(test_y1,test_yhat1[:,1]))\n",
        "\n",
        "# threshold = 0.225\n",
        "\n",
        "# train_output1 = (train_yhat1[:,1] > threshold).astype(int)\n",
        "# test_output1 = (test_yhat1[:,1] > threshold).astype(int)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(391836,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JC0Ta-QqqZF_",
        "outputId": "05fbb857-3936-407b-ef92-8bbc74d1e947"
      },
      "source": [
        "print(\"training score = \", f1_score(train_y1.astype(int), train_yhat1))\n",
        "print(\"testing score = \", f1_score(test_y1.astype(int), test_yhat1))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training score =  0.7080045989771241\n",
            "testing score =  0.5026308181555362\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ahYK5GlFrDAM"
      },
      "source": [
        "#### TD IDF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xv6XvunBrDxY"
      },
      "source": [
        "train_yhat2 = clf2.predict(train_X2)\n",
        "test_yhat2 = clf2.predict(test_X2)\n",
        "\n",
        "# print(\"training score = \", roc_auc_score(train_y2, train_yhat2[:,1]))\n",
        "# print(\"test score = \", roc_auc_score(test_y2,test_yhat2[:,1]))\n",
        "\n",
        "# threshold = 0.2\n",
        "\n",
        "# train_output2 = (train_yhat2[:,1] > threshold).astype(int)\n",
        "# test_output2 = (test_yhat2[:,1] > threshold).astype(int)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LEBfuT3zrPwJ",
        "outputId": "d165bc73-67d6-4d06-e6b5-53391f877d07"
      },
      "source": [
        "print(\"training score = \", f1_score(train_y2.astype(int), train_yhat2))\n",
        "print(\"testing score = \", f1_score(test_y2.astype(int), test_yhat2))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training score =  0.6661828167908984\n",
            "testing score =  0.4793756287918052\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbCXb8O8gl8g"
      },
      "source": [
        "# data = [[\"question_text\",\"target\"]]\n",
        "# for i in range(N):\n",
        "#   data.append([sentences[i],Y1[i]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZMKbuLLgl8g"
      },
      "source": [
        "# import csv\n",
        "\n",
        "# with open('processed_train_data.csv','w',newline='') as fp:\n",
        "#   a = csv.writer(fp, delimiter=',')\n",
        "#   a.writerows(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1FDG9zogl8h"
      },
      "source": [
        "#### Saving Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVaMC-9ugl8h"
      },
      "source": [
        "# import joblib\n",
        "\n",
        "# joblib.dump(lreg1,'Using Split LReg1 Model')\n",
        "# joblib.dump(lreg2,'Using Split LReg2 Model')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}