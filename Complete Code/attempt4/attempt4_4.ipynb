{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lx2nbe5zZ_-N"
      },
      "source": [
        "# AskReddit Troll Question Detection Challenge"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KXFHvvFiZ_-U"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "fhlIiuWBZ_-U"
      },
      "outputs": [],
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "rBUkOv3-Z_-Z"
      },
      "outputs": [],
      "source": [
        "train_df = pd.read_csv(\"processed_train_data.csv\")\n",
        "test_df = pd.read_csv(\"processed_test_data.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "cx1MhOldZ_-b"
      },
      "outputs": [],
      "source": [
        "sentences1 = train_df['question_text'].values.astype('U')\n",
        "sentences2 = test_df['question_text'].values.astype('U')\n",
        "sentences1 = sentences1.tolist()\n",
        "sentences2 = sentences2.tolist()\n",
        "sentences = []\n",
        "sentences = sentences1 + sentences2\n",
        "# train_df.head()\n",
        "# test_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZ3OL3ubZ_-c",
        "outputId": "6eb2fff1-001b-48f7-ce16-1998c332d3cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1218731\n",
            "653061\n",
            "1871792\n"
          ]
        }
      ],
      "source": [
        "print(len(sentences1))\n",
        "print(len(sentences2))\n",
        "N = len(sentences)\n",
        "# sentences = sentences[:N]\n",
        "print(len(sentences))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SGCFlwCKZ_-e"
      },
      "source": [
        "### Trying Methods"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7Q_4MUsZ_-f"
      },
      "source": [
        "#### Bag Of Words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "H2wvKev9Z_-f"
      },
      "outputs": [],
      "source": [
        "cv = CountVectorizer()\n",
        "X1 = cv.fit_transform(sentences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "vmSDQ3SQcgM0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'scipy.sparse.csr.csr_matrix'>\n",
            "int64\n",
            "float64\n"
          ]
        }
      ],
      "source": [
        "print(type(X1))\n",
        "print(X1.dtype)\n",
        "X1 = X1.astype(float)\n",
        "print(X1.dtype)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "IW7S45TpnoLu"
      },
      "outputs": [],
      "source": [
        "Y1 = train_df['target'].to_numpy().astype(np.float64)\n",
        "Y1 = Y1[:N]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-DL54RsIZ_-f"
      },
      "source": [
        "#### TF IDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "mslJKymTZ_-f"
      },
      "outputs": [],
      "source": [
        "cv = TfidfVectorizer()\n",
        "X2 = cv.fit_transform(sentences)\n",
        "# print(X2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Lj34PL32colU"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'scipy.sparse.csr.csr_matrix'>\n",
            "float64\n"
          ]
        }
      ],
      "source": [
        "print(type(X2))\n",
        "X2 = X2.astype(float)\n",
        "print(X2.dtype)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "nFKeWdk0oTw6"
      },
      "outputs": [],
      "source": [
        "Y2 = Y1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_X1 = X1[:len(sentences1),:]\n",
        "train_X2 = X2[:len(sentences1),:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_X1 = X1[len(sentences1):,:]\n",
        "test_X2 = X2[len(sentences1):,:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LWB94h8TZ_-g"
      },
      "source": [
        "#### Train test split data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "bsgQdc0DZ_-g"
      },
      "outputs": [],
      "source": [
        "# from sklearn.model_selection import train_test_split \n",
        "\n",
        "# train_X1, test_X1, train_y1, test_y1 = train_test_split(train_X1, Y1, train_size=0.6)\n",
        "\n",
        "# train_X2, test_X2, train_y2, test_y2 = train_test_split(train_X2, Y2, train_size=0.6)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eze130ezqBb_"
      },
      "source": [
        "#### Model generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "rn2kPLNFpKIB"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression \n",
        "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E6rUXyvQqIm-"
      },
      "source": [
        "#### For data genrated by \"Bag of words\" method  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "xuwqd1rAp3dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1218731, 179866)\n",
            "(1218731,)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "LogisticRegression(solver='liblinear')"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lreg1 = LogisticRegression(solver='liblinear')\n",
        "print(train_X1.shape)\n",
        "print(Y1.shape)\n",
        "lreg1.fit(train_X1,Y1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RUYqt4NSqU2n"
      },
      "source": [
        "#### For data generated by \"TD IDF\" method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "iGQrUb81p6yD"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "LogisticRegression(solver='liblinear')"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lreg2 = LogisticRegression(solver='liblinear')\n",
        "lreg2.fit(train_X2,Y2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9l8Fkxpa16hQ"
      },
      "source": [
        "### Predict for X1, Y1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "LUEcmzS71ogz"
      },
      "outputs": [],
      "source": [
        "test_yhat1 = lreg1.predict_proba(test_X1)\n",
        "\n",
        "# print(\"training score = \", roc_auc_score(train_y1, train_yhat1[:,1]))\n",
        "# print(\"test score = \", roc_auc_score(test_y1,test_yhat1[:,1]))\n",
        "\n",
        "threshold = 0.5\n",
        "\n",
        "test_output1 = (test_yhat1[:,1] > threshold).astype(int)\n",
        "\n",
        "# print(\"training score = \", roc_auc_score(train_y1, train_yhat1[:,1]))\n",
        "# print(\"test score = \", roc_auc_score(test_y1,test_yhat1[:,1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qE74zYa62MfV"
      },
      "source": [
        "### Predict for X2, Y2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "vdTbUQBz2QkI"
      },
      "outputs": [],
      "source": [
        "test_yhat2 = lreg2.predict_proba(test_X2)\n",
        "\n",
        "# print(\"training score = \", roc_auc_score(train_y2, train_yhat2[:,1]))\n",
        "# print(\"test score = \", roc_auc_score(test_y2,test_yhat2[:,1]))\n",
        "\n",
        "threshold = 0.5\n",
        "\n",
        "test_output2 = (test_yhat2[:,1] > threshold).astype(int)\n",
        "\n",
        "# print(\"training score = \", roc_auc_score(train_y2, train_yhat2[:,1]))\n",
        "# print(\"test score = \", roc_auc_score(test_y2,test_yhat2[:,1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(653061, 1)\n"
          ]
        }
      ],
      "source": [
        "test_output1 = test_output1.reshape(-1,1)\n",
        "test_output1 = test_output1.astype(int)\n",
        "print(test_output1.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "int64\n"
          ]
        }
      ],
      "source": [
        "test_output2 = test_output2.reshape(-1,1)\n",
        "test_output2 = test_output2.astype(int)\n",
        "print(test_output2.dtype)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Making a submission file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(653061, 2)\n"
          ]
        }
      ],
      "source": [
        "y_pred_df1 = pd.DataFrame(data=test_output1[:,0], columns = [\"target\"])\n",
        "submission_df1 = pd.concat([test_df[\"qid\"], y_pred_df1[\"target\"]], axis=1, join='inner')\n",
        "submission_df1.to_csv(\"submission1.csv\", index = False)\n",
        "print(submission_df1.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(653061, 2)\n"
          ]
        }
      ],
      "source": [
        "y_pred_df2 = pd.DataFrame(data=test_output2[:,0], columns = [\"target\"])\n",
        "submission_df2 = pd.concat([test_df[\"qid\"], y_pred_df2[\"target\"]], axis=1, join='inner')\n",
        "submission_df2.to_csv(\"submission2.csv\", index = False)\n",
        "print(submission_df2.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[     0 568112]\n",
            " [     1  84949]]\n"
          ]
        }
      ],
      "source": [
        "type(test_output1)\n",
        "\n",
        "unique, counts = np.unique(test_output1, return_counts=True)\n",
        "\n",
        "print(np.asarray((unique, counts)).T)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "v1.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
    },
    "kernelspec": {
      "display_name": "Python 3.8.10 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
